# -*- coding: utf-8 -*-
"""Water_Quality_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JJgCkfgBT_CZdWxIcCaDErTK7sfnCh9B
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('water_potability.csv')
df.head()

df.columns

df.describe()

df.info()

# for determining the count of missing data
df.isnull().sum()

plt.figure(figsize=(12,8))
sns.heatmap(df.isnull())

## Data Visualization
#Correlation Matrix
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(),annot=True)

#countplot = Create Bar plot
sns.countplot(x="Potability",data=df)

df["Potability"].value_counts()

#Visualization dataset also checking for Outliers

fig, ax = plt.subplots(ncols=5, nrows=2, figsize= (20,10))

# flatten()= This method is used to convert multidimensional arrays to a one-dimensional array.
ax= ax.flatten()

index= 0

for col, values in df.items():
  sns.boxplot(y= col, data= df, ax= ax[index])

  index +=1

sns.pairplot(df)

fig= px.pie(df, names= "Potability", hole= 0.4, template= "plotly_dark")
fig.show()

fig = px.scatter(df, x= "ph", y= "Sulfate", color="Potability", template= "plotly_dark")
fig.show()

##Filing NULL Values
# Calculates the percentage of null values ​​in each column.
df.isnull().mean().plot.bar(figsize= (6,6))
plt.xlabel("Features")
plt.ylabel("Percentage of missing values")

df["ph"]= df["ph"].fillna(df["ph"].mean())
df["Sulfate"]= df["Sulfate"].fillna(df["Sulfate"].mean())
df["Trihalomethanes"]= df["Trihalomethanes"].fillna(df["Trihalomethanes"].mean())

df.isnull().sum()

sns.heatmap(df.isnull())

## Data Preparations for Training Water Quality
x= df.drop("Potability", axis=1)
y= df["Potability"]

x.shape, y.shape

#This code snippet is performing data preprocessing, specifically standardization.
# scaling them to have a mean of 0 and a standard deviation of 1.
# fit: Calculates the mean and standard deviation of each feature in the x DataFrame.
# transform: Applies the calculated mean and standard deviation to standardize each feature in the x DataFrame.
scaler = StandardScaler()
x= scaler.fit_transform(x)
x

# Train, Test Split
x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2)

x_train.shape, x_test.shape

## Modeling Phase
# Logistic Regression ML
from sklearn.linear_model import LogisticRegression

# object of LR
model_lr= LogisticRegression()

# Training Model
model_lr.fit(x_train, y_train)

# Makeing Prediction
pred_lr= model_lr.predict(x_test)

# accuracy score
accuracy_score_lr= accuracy_score(y_test, pred_lr)
accuracy_score_lr

## Decision Tree Classifier ML
from sklearn.tree import DecisionTreeClassifier

# creating the model object
model_dt= DecisionTreeClassifier(max_depth= 4)

# Training of decision Tree
model_dt.fit(x_train, y_train)

# Making prediction using Decision Tree
pred_dt= model_dt.predict(x_test)

accuracy_score_dt= accuracy_score(y_test, pred_dt)
accuracy_score_dt

# Confusion matrix
cm2= confusion_matrix(y_test, pred_dt)
cm2

## Random Forest Classifiers ML
from sklearn.ensemble import RandomForestClassifier

# Creating the model object
model_rf = RandomForestClassifier()

# training Model RF
model_rf.fit(x_train, y_train)

# Making Prediction
pred_rf = model_rf.predict(x_test)

accuracy_score_rf= accuracy_score(y_test, pred_rf)
accuracy_score_rf

cm3= confusion_matrix(y_test, pred_rf)
cm3

## KNN -- K nearest neighbours
from sklearn.neighbors import KNeighborsClassifier

#Creating the Model Object
#model_knn= KNeighborsClassifier()

model_knn = KNeighborsClassifier(n_neighbors=11)
model_knn.fit(x_train, y_train)
pred_knn = model_knn.predict(x_test)
accuracy_score_knn = accuracy_score(y_test, pred_knn)
print(accuracy_score_knn)

## Suport Vector Machine
from sklearn.svm import SVC

# Creating Model Object
# we should select one kernel = rbf, linear, poly
model_svm = SVC(kernel = "rbf")

#Model training
model_svm.fit(x_train, y_train)

#Make Prediction
pred_svm= model_svm.predict(x_test)

# Calculating accuracy
accuracy_score_svm = accuracy_score(y_test, pred_svm)
accuracy_score_svm
accuracy_score_svm*100